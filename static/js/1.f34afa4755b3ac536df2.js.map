{"version":3,"sources":["webpack:///./src/components/GPReID.vue?8ae9","webpack:///./src/components/GPReID.vue"],"names":["GPReID","render","this","$createElement","_self","_c","_m","staticRenderFns","_vm","_h","staticClass","_v","attrs","href","Component","__webpack_require__","normalizeComponent","ssrContext","__webpack_exports__"],"mappings":"0HAAA,IAGeA,GADEC,OAFjB,WAA0BC,KAAaC,eAAbD,KAAuCE,MAAAC,GAAwB,OAA/DH,KAA+DI,GAAA,IAExEC,iBADjB,WAAoC,IAAAC,EAAAN,KAAaO,EAAAD,EAAAL,eAA0BE,EAAAG,EAAAJ,MAAAC,IAAAI,EAAwB,OAAAJ,EAAA,OAAiBK,YAAA,WAAqBL,EAAA,MAAAG,EAAAG,GAAA,uEAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAG,EAAAG,GAAA,wBAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAA,EAAA,KAAAG,EAAAG,GAAA,+BAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAG,EAAAG,GAAA,48BAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAG,EAAAG,GAAA,6VAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAA,EAAA,KAAAG,EAAAG,GAAA,2BAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAA,EAAA,MAAAG,EAAAG,GAAA,4FAAAN,EAAA,MAAAA,EAAA,MAAAG,EAAAG,GAAA,cAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAG,EAAAG,GAAA,wBAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAG,EAAAG,GAAA,uGAAAN,EAAA,MAAAA,EAAA,MAAAG,EAAAG,GAAA,cAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAG,EAAAG,GAAA,qEAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAG,EAAAG,GAAA,iEAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAG,EAAAG,GAAA,yGAAAN,EAAA,MAAAA,EAAA,MAAAG,EAAAG,GAAA,cAAAH,EAAAG,GAAA,KAAAN,EAAA,MAAAG,EAAAG,GAAA,8CAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAA,EAAA,KAAAG,EAAAG,GAAA,8BAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAG,EAAAG,GAAA,w/BAAAN,EAAA,KAAkgHO,OAAOC,KAAA,qCAA0CL,EAAAG,GAAA,uCAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAG,EAAAG,GAAA,sVAAAN,EAAA,KAAyaO,OAAOC,KAAA,wCAA6CL,EAAAG,GAAA,0CAAAH,EAAAG,GAAA,KAAAN,EAAA,KAAAG,EAAAG,GAAA,slBAAAN,EAAA,KAA4qBO,OAAOC,KAAA,4DAAiEL,EAAAG,GAAA,mECE74J,IAaAG,EAbyBC,EAAQ,OAajCC,CAXA,KAaEhB,GATF,EATA,SAAAiB,GACEF,EAAQ,SAYV,kBAEA,MAUeG,EAAA,QAAAJ,EAAiB","file":"static/js/1.f34afa4755b3ac536df2.js","sourcesContent":["var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0)}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"GPReID\"},[_c('h1',[_vm._v(\"Person Re-Identification: Synthetic Data And Model Generalization\")]),_vm._v(\" \"),_c('h3',[_vm._v(\"IJCB 2022 Tutorial\")]),_vm._v(\" \"),_c('p',[_c('b',[_vm._v(\"1. Tutorial Description\")])]),_vm._v(\" \"),_c('p',[_vm._v(\"Person re-identification is an active research topic in computer vision. It aims at finding the same person as the query image from a large volume of gallery images. With the progress in deep learning, person re-identification has been largely advanced in recent years. However, when generalization ability becomes an important concern, required by practical applications, existing methods usually lack satisfactory performance. To address this, many transfer learning, domain adaptation, and unsupervised learning methods, performed on the target domain, have been proposed. However, these methods require heavy computations in deployment, limiting their application in practical scenarios where the deployment machine may have limited resources to support deep learning and users may cannot wait for a time-consuming adaptation stage. Therefore, improving the baseline model’s generalization ability to support ready-to-use solutions is still of urgent importance.\")]),_vm._v(\" \"),_c('p',[_vm._v(\"In this tutorial, we will introduce the topic of generalizable person re-identification, from current challenges, the methods we have proposed, the effectiveness of large-scale synthesized dataset for generalizable person re-identification, to the reliability of using synthetic dataset for benchmarking generalizable person re-identification.\")]),_vm._v(\" \"),_c('p',[_c('b',[_vm._v(\"2. Tutorial Outline\")])]),_vm._v(\" \"),_c('ul',[_c('li',[_vm._v(\"\\n            Generalizable Person Re-Identification: Overview and Methods\\n            \"),_c('ul',[_c('li',[_vm._v(\"Overview\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Recent Methods\")])])]),_vm._v(\" \"),_c('li',[_vm._v(\"\\n            Synthetic Dataset Generation for Generalizable Person Re-Identification\\n            \"),_c('ul',[_c('li',[_vm._v(\"Overview\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Random 3D Characters for Generalizable Person Re-Identification\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Cloning Outfits from Real-World Images to 3D Characters\")])])]),_vm._v(\" \"),_c('li',[_vm._v(\"\\n            Synthetic Dataset for Benchmarking Generalizable Person Re-Identification\\n            \"),_c('ul',[_c('li',[_vm._v(\"Overview\")]),_vm._v(\" \"),_c('li',[_vm._v(\"Synthetic Dataset for Benchmarking\")])])])]),_vm._v(\" \"),_c('p',[_c('b',[_vm._v(\"3. Biography of Tutors\")])]),_vm._v(\" \"),_c('p',[_vm._v(\"Shengcai Liao is a Principal Scientist, and the Acting Director of R&D in Inception Institute of Artificial Intelligence (IIAI), UAE. He is a Senior Member of IEEE. Previously, he was an Associate Professor in Institute of Automation, Chinese Academy of Sciences (CASIA). He received B.S. degree in mathematics from Sun Yat-sen University in 2005 and Ph.D. degree from CASIA in 2010. He was a Postdoc in Michigan State University during 2010–2012. His research interests include object detection, recognition, and tracking, especially face and person analysis. He has published 100+ papers, with 16,800+ citations and h-index 46 (Google Scholar). He was awarded Best Student Paper in ICB 2006, ICB 2015, and CCBR 2016, Best Paper in ICB 2007, Best/Outstanding Reviewer in IJCB 2014, CVPR 2019/2021. He was an Assistant Editor for the book “Encyclopedia of Biometrics (2nd Ed.)”. He served as Program Chair for IJCB 2022, Area Chairs for ICPR 2016, ICB 2016/2018, and CVPR 2022, and SPC for IJCAI 2021. Homepage: \"),_c('a',{attrs:{\"href\":\"https://shengcailiao.github.io/\"}},[_vm._v(\"https://shengcailiao.github.io/\")])]),_vm._v(\" \"),_c('p',[_vm._v(\"Yanan Wang is a Research Engineer at the Inception Institute of Artificial Intelligence (IIAI). She got her master’s degree from the School of Electronic Engineering at Xidian University in 2018. Her current research interests include deep learning and computer vision. She has published two papers in ACMMM 2020 and CVPR 2022. Homepage: \"),_c('a',{attrs:{\"href\":\"https://yanan-wang-cs.github.io/#/\"}},[_vm._v(\"https://yanan-wang-cs.github.io/#/\")])]),_vm._v(\" \"),_c('p',[_vm._v(\"Cuicui Kang got her Ph.D. degree in Pattern Recognition and Intelligent Systems in 2015 at the National Laboratory of Pattern Recognition (NLPR) in the Institute of Automation, Chinese Academy of Sciences. Previously she was an Associate Professor in the Institute of Information Engineering, Chinese Academy of Sciences. Currently she works at MBZUAI as a research fellow. She published a number of papers in IEEE TMM, Neurocomputing, ACMMM, ACM CIKM, ACM ICMR, ACML, and so on. Besides, she was reviewers of lots of conferences and journals, such as IEEE TIFS, TMM, TIP, ECCV, etc. Homepage: \"),_c('a',{attrs:{\"href\":\"https://scholar.google.com/citations?user=aLO9l5MAAAAJ\"}},[_vm._v(\"https://scholar.google.com/citations?user=aLO9l5MAAAAJ\")])])])}]\nvar esExports = { render: render, staticRenderFns: staticRenderFns }\nexport default esExports\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./node_modules/vue-loader/lib/template-compiler?{\"id\":\"data-v-1ff83528\",\"hasScoped\":true,\"transformToRequire\":{\"video\":[\"src\",\"poster\"],\"source\":\"src\",\"img\":\"src\",\"image\":\"xlink:href\"},\"buble\":{\"transforms\":{}}}!./node_modules/vue-loader/lib/selector.js?type=template&index=0!./src/components/GPReID.vue\n// module id = null\n// module chunks = ","function injectStyle (ssrContext) {\n  require(\"!!../../node_modules/extract-text-webpack-plugin/dist/loader.js?{\\\"omit\\\":1,\\\"remove\\\":true}!vue-style-loader!css-loader?{\\\"sourceMap\\\":true}!../../node_modules/vue-loader/lib/style-compiler/index?{\\\"vue\\\":true,\\\"id\\\":\\\"data-v-1ff83528\\\",\\\"scoped\\\":true,\\\"hasInlineConfig\\\":false}!../../node_modules/vue-loader/lib/selector?type=styles&index=0!./GPReID.vue\")\n}\nvar normalizeComponent = require(\"!../../node_modules/vue-loader/lib/component-normalizer\")\n/* script */\nvar __vue_script__ = null\n/* template */\nimport __vue_template__ from \"!!../../node_modules/vue-loader/lib/template-compiler/index?{\\\"id\\\":\\\"data-v-1ff83528\\\",\\\"hasScoped\\\":true,\\\"transformToRequire\\\":{\\\"video\\\":[\\\"src\\\",\\\"poster\\\"],\\\"source\\\":\\\"src\\\",\\\"img\\\":\\\"src\\\",\\\"image\\\":\\\"xlink:href\\\"},\\\"buble\\\":{\\\"transforms\\\":{}}}!../../node_modules/vue-loader/lib/selector?type=template&index=0!./GPReID.vue\"\n/* template functional */\nvar __vue_template_functional__ = false\n/* styles */\nvar __vue_styles__ = injectStyle\n/* scopeId */\nvar __vue_scopeId__ = \"data-v-1ff83528\"\n/* moduleIdentifier (server only) */\nvar __vue_module_identifier__ = null\nvar Component = normalizeComponent(\n  __vue_script__,\n  __vue_template__,\n  __vue_template_functional__,\n  __vue_styles__,\n  __vue_scopeId__,\n  __vue_module_identifier__\n)\n\nexport default Component.exports\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./src/components/GPReID.vue\n// module id = null\n// module chunks = "],"sourceRoot":""}